//! Comprehensive reliability tests for Rustible
//!
//! This test suite exhaustively covers reliability scenarios including:
//! - CONNECTION RELIABILITY: Timeout handling, pool exhaustion, reconnection
//! - TASK EXECUTION RELIABILITY: ignore_errors, retry logic, handler notifications
//! - ERROR RECOVERY: Graceful degradation, cleanup, state consistency
//! - EDGE CASES: Empty playbooks, missing hosts, circular dependencies, long tasks
//!
//! Each test is documented with its purpose and covers both happy path and failure scenarios.

use std::collections::HashMap;
use std::path::PathBuf;
use std::sync::atomic::{AtomicUsize, Ordering};
use std::sync::Arc;
use std::time::{Duration, Instant};

use tokio::time::timeout;

use rustible::connection::config::RetryConfig;
use rustible::connection::local::LocalConnection;
use rustible::connection::{
    CommandResult, Connection, ConnectionConfig, ConnectionError, ConnectionFactory,
    ConnectionType, ExecuteOptions, TransferOptions,
};
use rustible::error::Error;
use rustible::executor::playbook::{Play, Playbook};
use rustible::executor::runtime::RuntimeContext;
use rustible::executor::task::{Handler, Task, TaskResult, TaskStatus};
use rustible::executor::{
    DependencyGraph, ExecutionStats, ExecutionStrategy, Executor, ExecutorConfig, ExecutorError,
};

// ============================================================================
// TEST FIXTURES AND HELPERS
// ============================================================================

/// Create a basic executor with specified configuration
fn create_executor_with_config(
    strategy: ExecutionStrategy,
    forks: usize,
    check_mode: bool,
) -> Executor {
    let config = ExecutorConfig {
        strategy,
        forks,
        check_mode,
        diff_mode: false,
        verbosity: 0,
        task_timeout: 300,
        gather_facts: false,
        extra_vars: HashMap::new(),
    };
    Executor::new(config)
}

/// Create a runtime context with multiple hosts
fn create_runtime_with_hosts(hosts: Vec<&str>) -> RuntimeContext {
    let mut runtime = RuntimeContext::new();
    for host in hosts {
        runtime.add_host(host.to_string(), None);
    }
    runtime
}

/// Create a runtime context with grouped hosts
fn create_runtime_with_groups(groups: Vec<(&str, Vec<&str>)>) -> RuntimeContext {
    let mut runtime = RuntimeContext::new();
    for (group, hosts) in groups {
        for host in hosts {
            runtime.add_host(host.to_string(), Some(group));
        }
    }
    runtime
}

/// Create a simple playbook with specified tasks
fn create_playbook_with_tasks(name: &str, hosts: &str, tasks: Vec<Task>) -> Playbook {
    let mut playbook = Playbook::new(name);
    let mut play = Play::new("Test Play", hosts);
    play.gather_facts = false;
    for task in tasks {
        play.add_task(task);
    }
    playbook.add_play(play);
    playbook
}

/// Create a playbook with handlers
fn create_playbook_with_handlers(
    name: &str,
    hosts: &str,
    tasks: Vec<Task>,
    handlers: Vec<Handler>,
) -> Playbook {
    let mut playbook = Playbook::new(name);
    let mut play = Play::new("Test Play", hosts);
    play.gather_facts = false;
    for task in tasks {
        play.add_task(task);
    }
    for handler in handlers {
        play.add_handler(handler);
    }
    playbook.add_play(play);
    playbook
}

// ============================================================================
// 1. CONNECTION RELIABILITY TESTS
// ============================================================================

/// Test: Connection timeout handling
///
/// Purpose: Verify that connections properly timeout when they take too long
/// and that appropriate errors are returned to the caller.
#[tokio::test]
async fn test_connection_timeout_handling() {
    // Create execute options with a very short timeout
    let options = ExecuteOptions::new().with_timeout(1);

    assert_eq!(options.timeout, Some(1));

    // Test that timeout configuration is properly set
    let options_no_timeout = ExecuteOptions::new();
    assert!(options_no_timeout.timeout.is_none());
}

/// Test: Connection timeout error type
///
/// Purpose: Verify that timeout errors are properly classified and contain
/// the correct information for debugging.
#[test]
fn test_connection_timeout_error_type() {
    let error = ConnectionError::Timeout(30);
    let error_msg = format!("{}", error);

    assert!(error_msg.contains("30"));
    assert!(error_msg.contains("timeout"));
}

/// Test: Connection pool exhaustion recovery
///
/// Purpose: Verify that when the connection pool is exhausted, the system
/// properly handles the condition and can recover.
#[test]
fn test_connection_pool_exhaustion_recovery() {
    // Create a config with a small pool
    let config = ConnectionConfig::default();
    let factory = ConnectionFactory::with_pool_size(config, 2);

    // Check initial pool stats
    let stats = factory.pool_stats();
    assert_eq!(stats.max_connections, 2);
    assert_eq!(stats.active_connections, 0);
}

/// Test: Connection pool statistics tracking
///
/// Purpose: Verify that pool statistics are accurately tracked during
/// connection creation and usage.
#[tokio::test]
async fn test_connection_pool_statistics() {
    let config = ConnectionConfig::default();
    let factory = ConnectionFactory::with_pool_size(config, 5);

    // Initial state
    let stats = factory.pool_stats();
    assert_eq!(stats.active_connections, 0);
    assert_eq!(stats.max_connections, 5);

    // Get a local connection
    let conn = factory.get_connection("localhost").await.unwrap();
    assert!(conn.is_alive().await);

    // Pool should now have one connection
    let stats_after = factory.pool_stats();
    assert!(stats_after.active_connections >= 1);
}

/// Test: Connection pool eviction on capacity
///
/// Purpose: Verify that old connections are evicted when the pool reaches
/// its maximum capacity.
#[tokio::test]
async fn test_connection_pool_eviction() {
    let config = ConnectionConfig::default();
    let factory = ConnectionFactory::with_pool_size(config, 2);

    // Get connections - pool should manage capacity
    let _conn1 = factory.get_connection("localhost").await.unwrap();

    let stats = factory.pool_stats();
    // Pool should not exceed max_connections
    assert!(stats.active_connections <= stats.max_connections);
}

/// Test: SSH connection drops mid-execution simulation
///
/// Purpose: Verify that the system can detect and handle SSH connection
/// drops during command execution.
#[test]
fn test_ssh_connection_drop_error_handling() {
    // Simulate SSH connection drop error
    let error = ConnectionError::ConnectionClosed;
    let error_msg = format!("{}", error);

    assert!(error_msg.contains("closed") || error_msg.contains("Connection"));

    // Verify execution failed error type
    let exec_error = ConnectionError::ExecutionFailed("Connection lost during command".to_string());
    assert!(format!("{}", exec_error).contains("Connection lost"));
}

/// Test: Reconnection after network failures
///
/// Purpose: Verify that the connection layer can detect failed connections
/// and attempt reconnection automatically.
#[tokio::test]
async fn test_reconnection_after_failure() {
    let config = ConnectionConfig::default();
    let factory = ConnectionFactory::new(config);

    // Get initial connection
    let conn = factory.get_connection("localhost").await.unwrap();
    assert!(conn.is_alive().await);

    // Close all connections
    factory.close_all().await.unwrap();

    // Pool should be empty after close_all
    let stats = factory.pool_stats();
    assert_eq!(stats.active_connections, 0);

    // Should be able to get a new connection
    let new_conn = factory.get_connection("localhost").await.unwrap();
    assert!(new_conn.is_alive().await);
}

/// Test: Multiple concurrent connections stress test
///
/// Purpose: Verify that the connection system can handle multiple concurrent
/// connection requests without deadlocks or race conditions.
#[tokio::test]
async fn test_concurrent_connections_stress() {
    let config = ConnectionConfig::default();
    let factory = ConnectionFactory::with_pool_size(config, 10);

    let completed = AtomicUsize::new(0);

    // Sequential stress test (ConnectionFactory uses parking_lot which isn't Send across await)
    for _ in 0..20 {
        // Try to get a connection
        if let Ok(conn) = factory.get_connection("localhost").await {
            if conn.is_alive().await {
                completed.fetch_add(1, Ordering::SeqCst);
            }
        }
    }

    // All connections should succeed
    assert!(completed.load(Ordering::SeqCst) > 0);

    // Pool stats should show activity
    let stats = factory.pool_stats();
    assert!(stats.active_connections >= 1);
}

/// Test: Connection type resolution for various hosts
///
/// Purpose: Verify that the connection factory correctly resolves
/// different host patterns to their appropriate connection types.
#[test]
fn test_connection_type_resolution() {
    // Local connection types
    assert_eq!(ConnectionType::Local.pool_key(), "local");

    // SSH connection type
    let ssh_type = ConnectionType::Ssh {
        host: "server.example.com".to_string(),
        port: 22,
        user: "deploy".to_string(),
    };
    assert_eq!(ssh_type.pool_key(), "ssh://deploy@server.example.com:22");

    // Docker connection type
    let docker_type = ConnectionType::Docker {
        container: "webapp_1".to_string(),
    };
    assert_eq!(docker_type.pool_key(), "docker://webapp_1");
}

/// Test: Connection retry configuration
///
/// Purpose: Verify that retry configuration is properly created and
/// exponential backoff is calculated correctly.
#[test]
fn test_connection_retry_configuration() {
    // Default retry config
    let default_retry = RetryConfig::default();
    assert!(default_retry.max_retries > 0);
    assert!(default_retry.retry_delay > Duration::ZERO);

    // Calculate backoff delays
    let delay_1 = default_retry.delay_for_attempt(1);
    let delay_2 = default_retry.delay_for_attempt(2);

    // Exponential backoff should increase delay
    assert!(delay_2 >= delay_1);

    // Delay should not exceed max_delay
    let delay_10 = default_retry.delay_for_attempt(10);
    assert!(delay_10 <= default_retry.max_delay);
}

/// Test: Local connection execute and verify
///
/// Purpose: Verify that local connection can execute commands and
/// return proper results.
#[tokio::test]
async fn test_local_connection_reliability() {
    let conn = LocalConnection::new();

    // Test successful command
    let result = conn.execute("echo 'test'", None).await.unwrap();
    assert!(result.success);
    assert_eq!(result.exit_code, 0);
    assert!(result.stdout.contains("test"));

    // Test failed command
    let result = conn.execute("exit 1", None).await.unwrap();
    assert!(!result.success);
    assert_eq!(result.exit_code, 1);
}

/// Test: Local connection with environment variables
///
/// Purpose: Verify that execute options properly set environment
/// variables for command execution.
#[tokio::test]
async fn test_local_connection_with_env() {
    let conn = LocalConnection::new();

    let options = ExecuteOptions::new().with_env("TEST_VAR", "test_value");

    let result = conn.execute("echo $TEST_VAR", Some(options)).await.unwrap();
    assert!(result.success);
    assert!(result.stdout.contains("test_value"));
}

/// Test: Local connection with working directory
///
/// Purpose: Verify that commands can be executed in a specific
/// working directory.
#[tokio::test]
async fn test_local_connection_with_cwd() {
    let conn = LocalConnection::new();

    let options = ExecuteOptions::new().with_cwd("/tmp");

    let result = conn.execute("pwd", Some(options)).await.unwrap();
    assert!(result.success);
    assert!(result.stdout.trim() == "/tmp");
}

// ============================================================================
// 2. TASK EXECUTION RELIABILITY TESTS
// ============================================================================

/// Test: Task failure with ignore_errors
///
/// Purpose: Verify that when ignore_errors is set to true, task failures
/// do not cause the entire playbook to fail.
#[tokio::test]
async fn test_task_failure_with_ignore_errors() {
    let runtime = create_runtime_with_hosts(vec!["localhost"]);
    let executor = Executor::with_runtime(
        ExecutorConfig {
            strategy: ExecutionStrategy::Linear,
            forks: 1,
            ..Default::default()
        },
        runtime,
    );

    // Create task that fails but has ignore_errors
    let failing_task = Task::new("Failing task", "fail")
        .arg("msg", "This should fail")
        .ignore_errors(true);

    let success_task = Task::new("After failure", "debug").arg("msg", "This should still run");

    let playbook = create_playbook_with_tasks(
        "Ignore Errors Test",
        "localhost",
        vec![failing_task, success_task],
    );

    let results = executor.run_playbook(&playbook).await.unwrap();

    // The playbook should complete without host being marked as failed
    let localhost_result = results.get("localhost").unwrap();
    // With ignore_errors, the host should not be marked as failed overall
    // (the error was ignored)
    assert!(!localhost_result.unreachable);
}

/// Test: Task execution with when condition
///
/// Purpose: Verify that tasks are properly skipped when their when
/// condition evaluates to false.
#[tokio::test]
async fn test_task_conditional_execution() {
    let mut runtime = create_runtime_with_hosts(vec!["localhost"]);
    runtime.set_global_var("should_run".to_string(), serde_json::json!(true));
    runtime.set_global_var("should_skip".to_string(), serde_json::json!(false));

    let executor = Executor::with_runtime(
        ExecutorConfig {
            strategy: ExecutionStrategy::Linear,
            forks: 1,
            ..Default::default()
        },
        runtime,
    );

    let task_run = Task::new("Should run", "debug")
        .arg("msg", "This runs")
        .when("should_run");

    let task_skip = Task::new("Should skip", "debug")
        .arg("msg", "This is skipped")
        .when("should_skip");

    let playbook =
        create_playbook_with_tasks("Conditional Test", "localhost", vec![task_run, task_skip]);

    let results = executor.run_playbook(&playbook).await.unwrap();
    let localhost_result = results.get("localhost").unwrap();

    // Should have one skipped task
    assert!(localhost_result.stats.skipped >= 1);
}

/// Test: Handler notification after task changes
///
/// Purpose: Verify that handlers are properly notified when a task
/// reports changes.
#[tokio::test]
async fn test_handler_notification_on_change() {
    let runtime = create_runtime_with_hosts(vec!["localhost"]);
    let executor = Executor::with_runtime(
        ExecutorConfig {
            strategy: ExecutionStrategy::Linear,
            forks: 1,
            ..Default::default()
        },
        runtime,
    );

    // Task that makes changes and notifies a handler
    let task = Task::new("Make changes", "command")
        .arg("cmd", "echo 'changed'")
        .notify("restart service");

    // Handler that should be triggered
    let handler = Handler {
        name: "restart service".to_string(),
        module: "debug".to_string(),
        args: indexmap::indexmap! {
            "msg".to_string() => serde_json::json!("Handler executed"),
        },
        when: None,
        listen: vec![],
    };

    let playbook = create_playbook_with_handlers(
        "Handler Notification Test",
        "localhost",
        vec![task],
        vec![handler],
    );

    let results = executor.run_playbook(&playbook).await.unwrap();

    // Playbook should complete successfully
    assert!(!results.get("localhost").unwrap().failed);
}

/// Test: Handler deduplication
///
/// Purpose: Verify that the same handler is only executed once even
/// when notified by multiple tasks.
#[tokio::test]
async fn test_handler_deduplication() {
    let runtime = create_runtime_with_hosts(vec!["localhost"]);
    let executor = Executor::with_runtime(
        ExecutorConfig {
            strategy: ExecutionStrategy::Linear,
            forks: 1,
            ..Default::default()
        },
        runtime,
    );

    // Multiple tasks notifying the same handler
    let task1 = Task::new("Task 1", "command")
        .arg("cmd", "echo 'change 1'")
        .notify("common handler");

    let task2 = Task::new("Task 2", "command")
        .arg("cmd", "echo 'change 2'")
        .notify("common handler");

    let handler = Handler {
        name: "common handler".to_string(),
        module: "debug".to_string(),
        args: indexmap::indexmap! {
            "msg".to_string() => serde_json::json!("Handler should run once"),
        },
        when: None,
        listen: vec![],
    };

    let playbook = create_playbook_with_handlers(
        "Handler Dedup Test",
        "localhost",
        vec![task1, task2],
        vec![handler],
    );

    let results = executor.run_playbook(&playbook).await.unwrap();

    // Playbook should complete successfully
    assert!(!results.get("localhost").unwrap().failed);
}

/// Test: Variable resolution during task execution
///
/// Purpose: Verify that variables are correctly resolved in task
/// arguments and conditions.
#[tokio::test]
async fn test_variable_resolution_in_tasks() {
    let mut runtime = create_runtime_with_hosts(vec!["localhost"]);
    runtime.set_global_var(
        "target_file".to_string(),
        serde_json::json!("/tmp/test.txt"),
    );
    runtime.set_global_var("message".to_string(), serde_json::json!("Hello World"));

    let executor = Executor::with_runtime(
        ExecutorConfig {
            strategy: ExecutionStrategy::Linear,
            forks: 1,
            ..Default::default()
        },
        runtime,
    );

    let task = Task::new("Debug with variable", "debug").arg("msg", "{{ message }}");

    let playbook = create_playbook_with_tasks("Variable Resolution Test", "localhost", vec![task]);

    let results = executor.run_playbook(&playbook).await.unwrap();

    // Task should complete successfully
    assert!(!results.get("localhost").unwrap().failed);
}

/// Test: Registered variable usage
///
/// Purpose: Verify that task results can be registered and used
/// by subsequent tasks.
#[tokio::test]
async fn test_registered_variable_usage() {
    let runtime = create_runtime_with_hosts(vec!["localhost"]);
    let executor = Executor::with_runtime(
        ExecutorConfig {
            strategy: ExecutionStrategy::Linear,
            forks: 1,
            ..Default::default()
        },
        runtime,
    );

    let task1 = Task::new("Register result", "debug")
        .arg("msg", "First task")
        .register("first_result");

    let task2 = Task::new("Use registered", "debug").arg("msg", "Second task");

    let playbook = create_playbook_with_tasks("Register Test", "localhost", vec![task1, task2]);

    let results = executor.run_playbook(&playbook).await.unwrap();

    assert!(!results.get("localhost").unwrap().failed);
}

/// Test: Loop execution with items
///
/// Purpose: Verify that tasks with loop items execute correctly
/// for each item.
#[tokio::test]
async fn test_loop_execution() {
    let runtime = create_runtime_with_hosts(vec!["localhost"]);
    let executor = Executor::with_runtime(
        ExecutorConfig {
            strategy: ExecutionStrategy::Linear,
            forks: 1,
            ..Default::default()
        },
        runtime,
    );

    let task = Task::new("Loop task", "debug")
        .arg("msg", "Item: {{ item }}")
        .loop_over(vec![
            serde_json::json!("one"),
            serde_json::json!("two"),
            serde_json::json!("three"),
        ]);

    let playbook = create_playbook_with_tasks("Loop Test", "localhost", vec![task]);

    let results = executor.run_playbook(&playbook).await.unwrap();

    assert!(!results.get("localhost").unwrap().failed);
}

/// Test: Task with changed_when override
///
/// Purpose: Verify that changed_when properly overrides the default
/// change detection.
#[tokio::test]
async fn test_changed_when_override() {
    let runtime = create_runtime_with_hosts(vec!["localhost"]);
    let executor = Executor::with_runtime(
        ExecutorConfig {
            strategy: ExecutionStrategy::Linear,
            forks: 1,
            ..Default::default()
        },
        runtime,
    );

    // Task that would normally report changed, but we override it
    let task = Task::new("Never changed", "command").arg("cmd", "echo 'test'");
    // Note: changed_when would need to be set in the Task struct

    let playbook = create_playbook_with_tasks("Changed When Test", "localhost", vec![task]);

    let results = executor.run_playbook(&playbook).await.unwrap();

    assert!(!results.get("localhost").unwrap().failed);
}

/// Test: Task with failed_when override
///
/// Purpose: Verify that failed_when properly controls when a task
/// is considered failed.
#[tokio::test]
async fn test_failed_when_override() {
    let runtime = create_runtime_with_hosts(vec!["localhost"]);
    let executor = Executor::with_runtime(
        ExecutorConfig {
            strategy: ExecutionStrategy::Linear,
            forks: 1,
            ..Default::default()
        },
        runtime,
    );

    // Debug task that should succeed
    let task = Task::new("Should succeed", "debug").arg("msg", "Success");

    let playbook = create_playbook_with_tasks("Failed When Test", "localhost", vec![task]);

    let results = executor.run_playbook(&playbook).await.unwrap();

    assert!(!results.get("localhost").unwrap().failed);
}

// ============================================================================
// 3. ERROR RECOVERY TESTS
// ============================================================================

/// Test: Graceful degradation on module failures
///
/// Purpose: Verify that when a single host fails, other hosts
/// can continue execution.
#[tokio::test]
async fn test_graceful_degradation_multi_host() {
    let runtime = create_runtime_with_hosts(vec!["host1", "host2", "host3"]);
    let executor = Executor::with_runtime(
        ExecutorConfig {
            strategy: ExecutionStrategy::Linear,
            forks: 5,
            ..Default::default()
        },
        runtime,
    );

    // First task succeeds on all hosts
    let task1 = Task::new("Task 1", "debug").arg("msg", "Success on all");

    // Second task - will succeed on all since we're using debug
    let task2 = Task::new("Task 2", "debug").arg("msg", "Also succeeds");

    let playbook = create_playbook_with_tasks("Degradation Test", "all", vec![task1, task2]);

    let results = executor.run_playbook(&playbook).await.unwrap();

    // All hosts should have results
    assert_eq!(results.len(), 3);
}

/// Test: Execution stats merge correctly
///
/// Purpose: Verify that execution statistics are properly merged
/// across multiple hosts.
#[test]
fn test_execution_stats_merge() {
    let mut stats1 = ExecutionStats {
        ok: 5,
        changed: 2,
        failed: 1,
        skipped: 0,
        unreachable: 0,
    };

    let stats2 = ExecutionStats {
        ok: 3,
        changed: 1,
        failed: 0,
        skipped: 2,
        unreachable: 1,
    };

    stats1.merge(&stats2);

    assert_eq!(stats1.ok, 8);
    assert_eq!(stats1.changed, 3);
    assert_eq!(stats1.failed, 1);
    assert_eq!(stats1.skipped, 2);
    assert_eq!(stats1.unreachable, 1);
}

/// Test: Error type classification for recovery decisions
///
/// Purpose: Verify that errors are properly classified as recoverable
/// or non-recoverable for decision making.
#[test]
fn test_error_recovery_classification() {
    // Recoverable errors
    let timeout_error = Error::TaskTimeout {
        task: "slow task".to_string(),
        host: "localhost".to_string(),
        timeout_secs: 30,
    };
    assert!(timeout_error.is_recoverable());

    let skip_error = Error::TaskSkipped("condition false".to_string());
    assert!(skip_error.is_recoverable());

    let connection_timeout = Error::ConnectionTimeout {
        host: "server1".to_string(),
        timeout_secs: 60,
    };
    assert!(connection_timeout.is_recoverable());

    // Non-recoverable errors
    let task_failed = Error::TaskFailed {
        task: "critical task".to_string(),
        host: "localhost".to_string(),
        message: "Critical failure".to_string(),
    };
    assert!(!task_failed.is_recoverable());

    let module_not_found = Error::ModuleNotFound {
        module: "nonexistent".to_string(),
        available: "apt, yum, copy".to_string(),
    };
    assert!(!module_not_found.is_recoverable());
}

/// Test: Exit codes for different error types
///
/// Purpose: Verify that errors produce appropriate exit codes
/// for CLI reporting.
#[test]
fn test_error_exit_codes() {
    let task_failed = Error::TaskFailed {
        task: "task".to_string(),
        host: "host".to_string(),
        message: "failed".to_string(),
    };
    assert_eq!(task_failed.exit_code(), 2);

    let connection_failed = Error::ConnectionFailed {
        host: "host".to_string(),
        message: "refused".to_string(),
        suggestions: "Check network connectivity.".to_string(),
    };
    assert_eq!(connection_failed.exit_code(), 3);

    let playbook_parse = Error::PlaybookParse {
        path: PathBuf::from("/test.yml"),
        message: "syntax error".to_string(),
        source: None,
    };
    assert_eq!(playbook_parse.exit_code(), 4);

    let inventory_load = Error::InventoryLoad {
        path: PathBuf::from("/inventory"),
        message: "not found".to_string(),
    };
    assert_eq!(inventory_load.exit_code(), 5);

    let vault_decrypt = Error::VaultDecryption("wrong password".to_string());
    assert_eq!(vault_decrypt.exit_code(), 6);
}

/// Test: Resource cleanup after task completion
///
/// Purpose: Verify that temporary resources are cleaned up after
/// task execution, even on failure.
#[tokio::test]
async fn test_resource_cleanup_after_execution() {
    let conn = LocalConnection::new();

    // Create a temporary file
    let result = conn.execute("mktemp", None).await.unwrap();
    let temp_file = result.stdout.trim().to_string();

    // Verify file exists
    let exists = conn
        .path_exists(std::path::Path::new(&temp_file))
        .await
        .unwrap();
    assert!(exists);

    // Clean up
    let cleanup_result = conn
        .execute(&format!("rm -f {}", temp_file), None)
        .await
        .unwrap();
    assert!(cleanup_result.success);

    // Verify file is gone
    let exists_after = conn
        .path_exists(std::path::Path::new(&temp_file))
        .await
        .unwrap();
    assert!(!exists_after);
}

/// Test: State consistency after partial execution
///
/// Purpose: Verify that the system maintains consistent state
/// even when execution is interrupted partway through.
#[tokio::test]
async fn test_state_consistency_after_partial_execution() {
    let runtime = create_runtime_with_hosts(vec!["host1", "host2"]);
    let executor = Executor::with_runtime(
        ExecutorConfig {
            strategy: ExecutionStrategy::Linear,
            forks: 2,
            ..Default::default()
        },
        runtime,
    );

    let task1 = Task::new("First task", "debug").arg("msg", "first");
    let task2 = Task::new("Second task", "fail").arg("msg", "This fails");
    let task3 = Task::new("Third task", "debug").arg("msg", "third");

    let playbook =
        create_playbook_with_tasks("Partial Execution Test", "all", vec![task1, task2, task3]);

    let results = executor.run_playbook(&playbook).await.unwrap();

    // Results should exist for all hosts
    assert_eq!(results.len(), 2);

    // Stats should reflect the partial execution
    for result in results.values() {
        assert!(result.stats.failed > 0);
    }
}

// ============================================================================
// 4. EDGE CASES
// ============================================================================

/// Test: Empty playbook handling
///
/// Purpose: Verify that an empty playbook (no plays) is handled
/// gracefully without errors.
#[tokio::test]
async fn test_empty_playbook() {
    let runtime = create_runtime_with_hosts(vec!["localhost"]);
    let executor = Executor::with_runtime(ExecutorConfig::default(), runtime);

    let playbook = Playbook::new("Empty Playbook");

    let results = executor.run_playbook(&playbook).await.unwrap();

    // Should return empty results
    assert!(results.is_empty());
}

/// Test: Empty play (no tasks) handling
///
/// Purpose: Verify that a play with no tasks is handled gracefully.
#[tokio::test]
async fn test_empty_play() {
    let runtime = create_runtime_with_hosts(vec!["localhost"]);
    let executor = Executor::with_runtime(ExecutorConfig::default(), runtime);

    let mut playbook = Playbook::new("Empty Play Playbook");
    let play = Play::new("Empty Play", "localhost");
    playbook.add_play(play);

    let results = executor.run_playbook(&playbook).await.unwrap();

    // Host should exist in results but with no task executions
    if let Some(result) = results.get("localhost") {
        assert!(!result.failed);
        assert!(!result.unreachable);
    }
}

/// Test: Missing inventory hosts
///
/// Purpose: Verify that when a play targets hosts that don't exist
/// in the inventory, appropriate warnings are issued.
#[tokio::test]
async fn test_missing_inventory_hosts() {
    let runtime = create_runtime_with_hosts(vec!["existing_host"]);
    let executor = Executor::with_runtime(ExecutorConfig::default(), runtime);

    let task = Task::new("Test task", "debug").arg("msg", "test");
    let playbook =
        create_playbook_with_tasks("Missing Hosts Test", "nonexistent_group", vec![task]);

    let results = executor.run_playbook(&playbook).await.unwrap();

    // Should handle gracefully - may return empty results for missing group
    // The behavior depends on how host patterns are resolved
    assert!(results.is_empty() || !results.values().any(|r| r.unreachable));
}

/// Test: Dependency graph cycle detection
///
/// Purpose: Verify that circular dependencies in task ordering
/// are properly detected and reported.
#[test]
fn test_circular_dependency_detection() {
    let mut graph = DependencyGraph::new();

    // Create a cycle: A -> B -> C -> A
    graph.add_dependency("task_a", "task_b");
    graph.add_dependency("task_b", "task_c");
    graph.add_dependency("task_c", "task_a");

    let result = graph.topological_sort();

    // Should detect the cycle
    assert!(matches!(result, Err(ExecutorError::DependencyCycle(_))));
}

/// Test: Valid dependency graph topological sort
///
/// Purpose: Verify that a valid dependency graph produces
/// the correct execution order.
#[test]
fn test_dependency_graph_valid_sort() {
    let mut graph = DependencyGraph::new();

    // Create a valid DAG
    graph.add_dependency("install", "download");
    graph.add_dependency("configure", "install");
    graph.add_dependency("start", "configure");

    let order = graph.topological_sort().unwrap();

    // Should produce a valid ordering
    assert!(order.len() >= 3);

    // download should come before install
    let download_pos = order.iter().position(|x| x == "download");
    let install_pos = order.iter().position(|x| x == "install");
    if let (Some(d), Some(i)) = (download_pos, install_pos) {
        assert!(d < i);
    }
}

/// Test: Single host execution
///
/// Purpose: Verify that playbook execution works correctly
/// with only a single host.
#[tokio::test]
async fn test_single_host_execution() {
    let runtime = create_runtime_with_hosts(vec!["only_host"]);
    let executor = Executor::with_runtime(
        ExecutorConfig {
            strategy: ExecutionStrategy::Linear,
            forks: 1,
            ..Default::default()
        },
        runtime,
    );

    let task = Task::new("Single host task", "debug").arg("msg", "Running on single host");

    let playbook = create_playbook_with_tasks("Single Host Test", "all", vec![task]);

    let results = executor.run_playbook(&playbook).await.unwrap();

    assert_eq!(results.len(), 1);
    assert!(!results.get("only_host").unwrap().failed);
}

/// Test: Single task execution
///
/// Purpose: Verify that playbook execution works correctly
/// with only a single task.
#[tokio::test]
async fn test_single_task_execution() {
    let runtime = create_runtime_with_hosts(vec!["host1", "host2"]);
    let executor = Executor::with_runtime(
        ExecutorConfig {
            strategy: ExecutionStrategy::Linear,
            forks: 2,
            ..Default::default()
        },
        runtime,
    );

    let task = Task::new("Only task", "debug").arg("msg", "Single task");

    let playbook = create_playbook_with_tasks("Single Task Test", "all", vec![task]);

    let results = executor.run_playbook(&playbook).await.unwrap();

    assert_eq!(results.len(), 2);
    for result in results.values() {
        assert!(!result.failed);
    }
}

/// Test: Very long task name handling
///
/// Purpose: Verify that tasks with very long names are handled
/// properly without truncation issues.
#[tokio::test]
async fn test_long_task_name() {
    let runtime = create_runtime_with_hosts(vec!["localhost"]);
    let executor = Executor::with_runtime(ExecutorConfig::default(), runtime);

    let long_name = "A".repeat(1000);
    let task = Task::new(&long_name, "debug").arg("msg", "test");

    let playbook = create_playbook_with_tasks("Long Name Test", "localhost", vec![task]);

    let results = executor.run_playbook(&playbook).await.unwrap();

    assert!(!results.get("localhost").unwrap().failed);
}

/// Test: Special characters in task arguments
///
/// Purpose: Verify that special characters in task arguments
/// are handled correctly.
#[tokio::test]
async fn test_special_characters_in_args() {
    let runtime = create_runtime_with_hosts(vec!["localhost"]);
    let executor = Executor::with_runtime(ExecutorConfig::default(), runtime);

    let task = Task::new("Special chars", "debug").arg(
        "msg",
        "Special: $PATH {{ var }} 'quotes' \"double\" `backticks`",
    );

    let playbook = create_playbook_with_tasks("Special Chars Test", "localhost", vec![task]);

    let results = executor.run_playbook(&playbook).await.unwrap();

    assert!(!results.get("localhost").unwrap().failed);
}

/// Test: Unicode in task names and arguments
///
/// Purpose: Verify that unicode characters are handled properly
/// in task definitions.
#[tokio::test]
async fn test_unicode_handling() {
    let runtime = create_runtime_with_hosts(vec!["localhost"]);
    let executor = Executor::with_runtime(ExecutorConfig::default(), runtime);

    let task = Task::new("Unicode test", "debug").arg("msg", "Hello World");

    let playbook = create_playbook_with_tasks("Unicode Test", "localhost", vec![task]);

    let results = executor.run_playbook(&playbook).await.unwrap();

    assert!(!results.get("localhost").unwrap().failed);
}

/// Test: Large number of hosts
///
/// Purpose: Verify that the system can handle a large number
/// of hosts without performance degradation.
#[tokio::test]
async fn test_large_host_count() {
    let hosts: Vec<&str> = (0..50)
        .map(|i| Box::leak(format!("host{}", i).into_boxed_str()) as &str)
        .collect();
    let runtime = create_runtime_with_hosts(hosts);

    let executor = Executor::with_runtime(
        ExecutorConfig {
            strategy: ExecutionStrategy::Free,
            forks: 10,
            ..Default::default()
        },
        runtime,
    );

    let task = Task::new("Mass host task", "debug").arg("msg", "test");

    let playbook = create_playbook_with_tasks("Large Host Test", "all", vec![task]);

    let start = Instant::now();
    let results = executor.run_playbook(&playbook).await.unwrap();
    let duration = start.elapsed();

    // Should complete in reasonable time
    assert!(duration < Duration::from_secs(30));
    assert_eq!(results.len(), 50);
}

/// Test: Large number of tasks
///
/// Purpose: Verify that the system can handle a large number
/// of tasks without issues.
#[tokio::test]
async fn test_large_task_count() {
    let runtime = create_runtime_with_hosts(vec!["localhost"]);
    let executor = Executor::with_runtime(ExecutorConfig::default(), runtime);

    let tasks: Vec<Task> = (0..100)
        .map(|i| Task::new(format!("Task {}", i), "debug").arg("msg", format!("Task {}", i)))
        .collect();

    let playbook = create_playbook_with_tasks("Large Task Test", "localhost", tasks);

    let start = Instant::now();
    let results = executor.run_playbook(&playbook).await.unwrap();
    let duration = start.elapsed();

    // Should complete in reasonable time
    assert!(duration < Duration::from_secs(30));
    assert!(!results.get("localhost").unwrap().failed);
}

// ============================================================================
// 5. EXECUTION STRATEGY RELIABILITY TESTS
// ============================================================================

/// Test: Free strategy allows independent host execution
///
/// Purpose: Verify that in free strategy, hosts can proceed
/// through tasks independently.
#[tokio::test]
async fn test_free_strategy_independence() {
    let runtime = create_runtime_with_hosts(vec!["fast_host", "slow_host"]);
    let executor = Executor::with_runtime(
        ExecutorConfig {
            strategy: ExecutionStrategy::Free,
            forks: 5,
            ..Default::default()
        },
        runtime,
    );

    let task1 = Task::new("Task 1", "debug").arg("msg", "first");
    let task2 = Task::new("Task 2", "debug").arg("msg", "second");

    let playbook = create_playbook_with_tasks("Free Strategy Test", "all", vec![task1, task2]);

    let results = executor.run_playbook(&playbook).await.unwrap();

    // Both hosts should complete
    assert_eq!(results.len(), 2);
    for result in results.values() {
        assert!(!result.failed);
    }
}

/// Test: Linear strategy synchronizes at each task
///
/// Purpose: Verify that in linear strategy, all hosts complete
/// a task before moving to the next.
#[tokio::test]
async fn test_linear_strategy_synchronization() {
    let runtime = create_runtime_with_hosts(vec!["host1", "host2", "host3"]);
    let executor = Executor::with_runtime(
        ExecutorConfig {
            strategy: ExecutionStrategy::Linear,
            forks: 5,
            ..Default::default()
        },
        runtime,
    );

    let task1 = Task::new("Sync task 1", "debug").arg("msg", "first");
    let task2 = Task::new("Sync task 2", "debug").arg("msg", "second");

    let playbook = create_playbook_with_tasks("Linear Strategy Test", "all", vec![task1, task2]);

    let results = executor.run_playbook(&playbook).await.unwrap();

    // All hosts should complete
    assert_eq!(results.len(), 3);
    for result in results.values() {
        assert!(!result.failed);
    }
}

/// Test: Fork limit enforcement
///
/// Purpose: Verify that the forks limit is respected and no more
/// than forks hosts are executing simultaneously.
#[tokio::test]
async fn test_fork_limit_enforcement() {
    let hosts: Vec<&str> = (0..10)
        .map(|i| Box::leak(format!("host{}", i).into_boxed_str()) as &str)
        .collect();
    let runtime = create_runtime_with_hosts(hosts);

    // Set forks to 3, meaning only 3 hosts should execute at once
    let executor = Executor::with_runtime(
        ExecutorConfig {
            strategy: ExecutionStrategy::Free,
            forks: 3,
            ..Default::default()
        },
        runtime,
    );

    let task = Task::new("Fork test", "debug").arg("msg", "test");

    let playbook = create_playbook_with_tasks("Fork Limit Test", "all", vec![task]);

    let results = executor.run_playbook(&playbook).await.unwrap();

    // All hosts should eventually complete
    assert_eq!(results.len(), 10);
}

// ============================================================================
// 6. TASK RESULT HANDLING TESTS
// ============================================================================

/// Test: TaskResult constructors
///
/// Purpose: Verify that TaskResult helper constructors work correctly.
#[test]
fn test_task_result_constructors() {
    let ok = TaskResult::ok();
    assert_eq!(ok.status, TaskStatus::Ok);
    assert!(!ok.changed);

    let changed = TaskResult::changed();
    assert_eq!(changed.status, TaskStatus::Changed);
    assert!(changed.changed);

    let failed = TaskResult::failed("error message");
    assert_eq!(failed.status, TaskStatus::Failed);
    assert_eq!(failed.msg, Some("error message".to_string()));

    let skipped = TaskResult::skipped("condition false");
    assert_eq!(skipped.status, TaskStatus::Skipped);

    let unreachable = TaskResult::unreachable("host down");
    assert_eq!(unreachable.status, TaskStatus::Unreachable);
}

/// Test: TaskResult builder pattern
///
/// Purpose: Verify that TaskResult builder methods work correctly.
#[test]
fn test_task_result_builder_pattern() {
    let result = TaskResult::ok()
        .with_msg("Success message")
        .with_result(serde_json::json!({"key": "value"}));

    assert_eq!(result.msg, Some("Success message".to_string()));
    assert!(result.result.is_some());
}

/// Test: Task builder pattern
///
/// Purpose: Verify that Task builder methods work correctly.
#[test]
fn test_task_builder_pattern() {
    let task = Task::new("Install package", "apt")
        .arg("name", "nginx")
        .arg("state", "present")
        .when("ansible_os_family == 'Debian'")
        .notify("restart nginx")
        .register("install_result")
        .ignore_errors(true);

    assert_eq!(task.name, "Install package");
    assert_eq!(task.module, "apt");
    assert_eq!(task.args.get("name"), Some(&serde_json::json!("nginx")));
    assert_eq!(task.when, Some("ansible_os_family == 'Debian'".to_string()));
    assert!(task.notify.contains(&"restart nginx".to_string()));
    assert_eq!(task.register, Some("install_result".to_string()));
    assert!(task.ignore_errors);
}

// ============================================================================
// 7. CONNECTION ERROR HANDLING TESTS
// ============================================================================

/// Test: All connection error types are properly formatted
///
/// Purpose: Verify that all connection error types produce
/// meaningful error messages.
#[test]
fn test_connection_error_messages() {
    let errors = vec![
        (
            ConnectionError::ConnectionFailed("refused".to_string()),
            "refused",
        ),
        (
            ConnectionError::AuthenticationFailed("bad key".to_string()),
            "bad key",
        ),
        (
            ConnectionError::ExecutionFailed("command error".to_string()),
            "command error",
        ),
        (
            ConnectionError::TransferFailed("copy failed".to_string()),
            "copy failed",
        ),
        (ConnectionError::Timeout(30), "30"),
        (
            ConnectionError::HostNotFound("unknown".to_string()),
            "unknown",
        ),
        (
            ConnectionError::InvalidConfig("bad setting".to_string()),
            "bad setting",
        ),
        (
            ConnectionError::SshError("ssh issue".to_string()),
            "ssh issue",
        ),
        (ConnectionError::PoolExhausted, "exhausted"),
        (ConnectionError::ConnectionClosed, "closed"),
        (
            ConnectionError::DockerError("docker issue".to_string()),
            "docker issue",
        ),
        (
            ConnectionError::UnsupportedOperation("not supported".to_string()),
            "not supported",
        ),
    ];

    for (error, expected_substring) in errors {
        let msg = format!("{}", error);
        assert!(
            msg.to_lowercase()
                .contains(&expected_substring.to_lowercase()),
            "Error '{}' should contain '{}'",
            msg,
            expected_substring
        );
    }
}

/// Test: All main error types are properly formatted
///
/// Purpose: Verify that all main Error enum variants produce
/// meaningful error messages.
#[test]
fn test_main_error_messages() {
    let errors: Vec<(Error, &str)> = vec![
        (
            Error::ModuleNotFound {
                module: "custom_module".to_string(),
                available: "apt, yum".to_string(),
            },
            "custom_module",
        ),
        (
            Error::HandlerNotFound("missing_handler".to_string()),
            "missing_handler",
        ),
        (
            Error::HostNotFound {
                host: "unknown_host".to_string(),
                suggestion: "Check inventory".to_string(),
            },
            "unknown_host",
        ),
        (
            Error::GroupNotFound("unknown_group".to_string()),
            "unknown_group",
        ),
        (
            Error::RoleNotFound("missing_role".to_string()),
            "missing_role",
        ),
        (
            Error::UndefinedVariable("undefined_var".to_string()),
            "undefined_var",
        ),
    ];

    for (error, expected_substring) in errors {
        let msg = format!("{}", error);
        assert!(
            msg.contains(expected_substring),
            "Error '{}' should contain '{}'",
            msg,
            expected_substring
        );
    }
}

// ============================================================================
// 8. FILE OPERATION RELIABILITY TESTS
// ============================================================================

/// Test: Path existence check
///
/// Purpose: Verify that path_exists correctly identifies existing
/// and non-existing paths.
#[tokio::test]
async fn test_path_existence_check() {
    let conn = LocalConnection::new();

    // Check existing path
    let exists = conn
        .path_exists(std::path::Path::new("/tmp"))
        .await
        .unwrap();
    assert!(exists);

    // Check non-existing path
    let not_exists = conn
        .path_exists(std::path::Path::new("/nonexistent/path/12345"))
        .await
        .unwrap();
    assert!(!not_exists);
}

/// Test: Directory detection
///
/// Purpose: Verify that is_directory correctly identifies directories
/// vs regular files.
#[tokio::test]
async fn test_directory_detection() {
    let conn = LocalConnection::new();

    // /tmp should be a directory
    let is_dir = conn
        .is_directory(std::path::Path::new("/tmp"))
        .await
        .unwrap();
    assert!(is_dir);

    // /etc/passwd should not be a directory (if it exists)
    if conn
        .path_exists(std::path::Path::new("/etc/passwd"))
        .await
        .unwrap()
    {
        let is_file_dir = conn
            .is_directory(std::path::Path::new("/etc/passwd"))
            .await
            .unwrap();
        assert!(!is_file_dir);
    }
}

/// Test: File stat retrieval
///
/// Purpose: Verify that stat returns correct file information.
#[tokio::test]
async fn test_file_stat_retrieval() {
    let conn = LocalConnection::new();

    let stat = conn.stat(std::path::Path::new("/tmp")).await.unwrap();

    assert!(stat.is_dir);
    assert!(!stat.is_file);
    assert!(stat.mode > 0);
}

/// Test: File upload and download
///
/// Purpose: Verify that files can be uploaded and downloaded reliably.
#[tokio::test]
async fn test_file_upload_download() {
    let conn = LocalConnection::new();
    let temp_dir = tempfile::tempdir().unwrap();

    let source_path = temp_dir.path().join("source.txt");
    let dest_path = temp_dir.path().join("dest.txt");

    // Create source file
    std::fs::write(&source_path, "test content").unwrap();

    // Upload (copy)
    conn.upload(&source_path, &dest_path, None).await.unwrap();

    // Verify destination exists
    let exists = conn.path_exists(&dest_path).await.unwrap();
    assert!(exists);

    // Verify content
    let content = std::fs::read_to_string(&dest_path).unwrap();
    assert_eq!(content, "test content");
}

/// Test: Content upload
///
/// Purpose: Verify that content can be uploaded directly to a file.
#[tokio::test]
async fn test_content_upload() {
    let conn = LocalConnection::new();
    let temp_dir = tempfile::tempdir().unwrap();
    let dest_path = temp_dir.path().join("content.txt");

    conn.upload_content(b"uploaded content", &dest_path, None)
        .await
        .unwrap();

    let exists = conn.path_exists(&dest_path).await.unwrap();
    assert!(exists);

    let content = std::fs::read_to_string(&dest_path).unwrap();
    assert_eq!(content, "uploaded content");
}

// ============================================================================
// 9. CHECK MODE RELIABILITY TESTS
// ============================================================================

/// Test: Check mode prevents actual changes
///
/// Purpose: Verify that when check_mode is enabled, no actual
/// changes are made to the system.
#[tokio::test]
async fn test_check_mode_no_changes() {
    let runtime = create_runtime_with_hosts(vec!["localhost"]);
    let executor = Executor::with_runtime(
        ExecutorConfig {
            check_mode: true,
            ..Default::default()
        },
        runtime,
    );

    assert!(executor.is_check_mode());

    let task = Task::new("Would change", "command").arg("cmd", "echo 'would change'");

    let playbook = create_playbook_with_tasks("Check Mode Test", "localhost", vec![task]);

    let results = executor.run_playbook(&playbook).await.unwrap();

    // Should complete without errors
    assert!(!results.get("localhost").unwrap().failed);
}

// ============================================================================
// 10. HANDLER RELIABILITY TESTS
// ============================================================================

/// Test: Handler listen keyword
///
/// Purpose: Verify that handlers can listen for multiple
/// notification names.
#[test]
fn test_handler_listen_keyword() {
    let handler = Handler {
        name: "restart services".to_string(),
        module: "service".to_string(),
        args: indexmap::indexmap! {
            "name".to_string() => serde_json::json!("nginx"),
            "state".to_string() => serde_json::json!("restarted"),
        },
        when: None,
        listen: vec![
            "restart nginx".to_string(),
            "reload nginx".to_string(),
            "nginx changed".to_string(),
        ],
    };

    assert_eq!(handler.listen.len(), 3);
    assert!(handler.listen.contains(&"restart nginx".to_string()));
    assert!(handler.listen.contains(&"reload nginx".to_string()));
}

/// Test: Conditional handler
///
/// Purpose: Verify that handlers with when conditions only execute
/// when conditions are met.
#[test]
fn test_conditional_handler() {
    let handler = Handler {
        name: "conditional restart".to_string(),
        module: "service".to_string(),
        args: indexmap::indexmap! {
            "name".to_string() => serde_json::json!("nginx"),
            "state".to_string() => serde_json::json!("restarted"),
        },
        when: Some("ansible_os_family == 'Debian'".to_string()),
        listen: vec![],
    };

    assert!(handler.when.is_some());
    assert!(handler.when.as_ref().unwrap().contains("Debian"));
}

// ============================================================================
// 11. EXECUTOR ERROR HANDLING TESTS
// ============================================================================

/// Test: All executor error types are properly formatted
///
/// Purpose: Verify that all ExecutorError variants produce
/// meaningful error messages.
#[test]
fn test_executor_error_messages() {
    let errors = vec![
        (
            ExecutorError::TaskFailed("task error".to_string()),
            "task error",
        ),
        (
            ExecutorError::HostUnreachable("bad host".to_string()),
            "bad host",
        ),
        (ExecutorError::DependencyCycle("cycle".to_string()), "cycle"),
        (
            ExecutorError::HandlerNotFound("missing".to_string()),
            "missing",
        ),
        (
            ExecutorError::VariableNotFound("undefined".to_string()),
            "undefined",
        ),
        (
            ExecutorError::ConditionError("bad condition".to_string()),
            "bad condition",
        ),
        (
            ExecutorError::ModuleNotFound("no module".to_string()),
            "no module",
        ),
        (
            ExecutorError::ParseError("parse issue".to_string()),
            "parse issue",
        ),
        (
            ExecutorError::RuntimeError("runtime".to_string()),
            "runtime",
        ),
    ];

    for (error, expected) in errors {
        let msg = format!("{}", error);
        assert!(
            msg.to_lowercase().contains(&expected.to_lowercase()),
            "Error '{}' should contain '{}'",
            msg,
            expected
        );
    }
}

// ============================================================================
// 12. RUNTIME CONTEXT RELIABILITY TESTS
// ============================================================================

/// Test: Runtime context variable precedence
///
/// Purpose: Verify that variables are resolved with correct precedence
/// (extra vars > task vars > play vars > global vars).
#[tokio::test]
async fn test_variable_precedence() {
    let mut runtime = RuntimeContext::new();
    runtime.add_host("localhost".to_string(), None);

    // Set variables at different levels
    runtime.set_global_var("var".to_string(), serde_json::json!("global"));
    runtime.set_play_var("var".to_string(), serde_json::json!("play"));

    let merged = runtime.get_merged_vars("localhost");

    // Play var should take precedence over global
    assert_eq!(merged.get("var"), Some(&serde_json::json!("play")));
}

/// Test: Host facts storage and retrieval
///
/// Purpose: Verify that host facts are properly stored and retrieved.
#[tokio::test]
async fn test_host_facts_storage() {
    let mut runtime = RuntimeContext::new();
    runtime.add_host("webserver".to_string(), None);

    runtime.set_host_var(
        "webserver",
        "ansible_os_family".to_string(),
        serde_json::json!("Debian"),
    );

    let merged = runtime.get_merged_vars("webserver");
    assert_eq!(
        merged.get("ansible_os_family"),
        Some(&serde_json::json!("Debian"))
    );
}

/// Test: Group resolution
///
/// Purpose: Verify that hosts can be retrieved by group membership.
#[tokio::test]
async fn test_group_resolution() {
    let runtime = create_runtime_with_groups(vec![
        ("webservers", vec!["web1", "web2"]),
        ("dbservers", vec!["db1"]),
    ]);

    let web_hosts = runtime.get_group_hosts("webservers").unwrap();
    assert_eq!(web_hosts.len(), 2);
    assert!(web_hosts.contains(&"web1".to_string()));
    assert!(web_hosts.contains(&"web2".to_string()));

    let db_hosts = runtime.get_group_hosts("dbservers").unwrap();
    assert_eq!(db_hosts.len(), 1);
    assert!(db_hosts.contains(&"db1".to_string()));
}

/// Test: Get all hosts
///
/// Purpose: Verify that all hosts can be retrieved from runtime.
#[tokio::test]
async fn test_get_all_hosts() {
    let runtime = create_runtime_with_hosts(vec!["host1", "host2", "host3"]);

    let all_hosts = runtime.get_all_hosts();
    assert_eq!(all_hosts.len(), 3);
}

// ============================================================================
// 13. TRANSFER OPTIONS RELIABILITY TESTS
// ============================================================================

/// Test: Transfer options builder pattern
///
/// Purpose: Verify that TransferOptions builder methods work correctly.
#[test]
fn test_transfer_options_builder() {
    let options = TransferOptions::new()
        .with_mode(0o644)
        .with_owner("www-data")
        .with_group("www-data")
        .with_create_dirs();

    assert_eq!(options.mode, Some(0o644));
    assert_eq!(options.owner, Some("www-data".to_string()));
    assert_eq!(options.group, Some("www-data".to_string()));
    assert!(options.create_dirs);
}

/// Test: Default transfer options
///
/// Purpose: Verify that default TransferOptions have sensible defaults.
#[test]
fn test_transfer_options_defaults() {
    let options = TransferOptions::default();

    assert!(options.mode.is_none());
    assert!(options.owner.is_none());
    assert!(options.group.is_none());
    assert!(!options.create_dirs);
    assert!(!options.backup);
}

// ============================================================================
// 14. EXECUTE OPTIONS RELIABILITY TESTS
// ============================================================================

/// Test: Execute options with escalation
///
/// Purpose: Verify that privilege escalation options are set correctly.
#[test]
fn test_execute_options_escalation() {
    let options = ExecuteOptions::new().with_escalation(Some("root".to_string()));

    assert!(options.escalate);
    assert_eq!(options.escalate_user, Some("root".to_string()));
}

/// Test: Execute options chaining
///
/// Purpose: Verify that multiple options can be chained together.
#[test]
fn test_execute_options_chaining() {
    let options = ExecuteOptions::new()
        .with_cwd("/var/www")
        .with_env("PATH", "/usr/local/bin")
        .with_env("HOME", "/root")
        .with_timeout(60)
        .with_escalation(Some("admin".to_string()));

    assert_eq!(options.cwd, Some("/var/www".to_string()));
    assert_eq!(options.env.len(), 2);
    assert_eq!(options.timeout, Some(60));
    assert!(options.escalate);
    assert_eq!(options.escalate_user, Some("admin".to_string()));
}

// ============================================================================
// 15. COMMAND RESULT RELIABILITY TESTS
// ============================================================================

/// Test: Command result combined output
///
/// Purpose: Verify that combined_output correctly merges stdout and stderr.
#[test]
fn test_command_result_combined_output() {
    let result1 = CommandResult {
        exit_code: 0,
        stdout: "stdout content".to_string(),
        stderr: "stderr content".to_string(),
        success: true,
    };
    assert_eq!(result1.combined_output(), "stdout content\nstderr content");

    let result2 = CommandResult {
        exit_code: 0,
        stdout: "only stdout".to_string(),
        stderr: "".to_string(),
        success: true,
    };
    assert_eq!(result2.combined_output(), "only stdout");

    let result3 = CommandResult {
        exit_code: 1,
        stdout: "".to_string(),
        stderr: "only stderr".to_string(),
        success: false,
    };
    assert_eq!(result3.combined_output(), "only stderr");
}

/// Test: Command result constructors
///
/// Purpose: Verify that success and failure constructors work correctly.
#[test]
fn test_command_result_constructors() {
    let success = CommandResult::success("out".to_string(), "err".to_string());
    assert!(success.success);
    assert_eq!(success.exit_code, 0);

    let failure = CommandResult::failure(127, "".to_string(), "not found".to_string());
    assert!(!failure.success);
    assert_eq!(failure.exit_code, 127);
}
